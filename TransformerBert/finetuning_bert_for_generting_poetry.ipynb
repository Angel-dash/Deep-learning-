{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lzH3tn6wyb4Z"
      },
      "outputs": [],
      "source": [
        "# !pip install wget\n",
        "!pip install torch -q\n",
        "!pip install transformers -q\n",
        "!pip install datasets -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "DWnbuqP3AWCT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  device_count = torch.cuda.device_count()\n",
        "  device_name = torch.cuda.get_device_name(0)\n",
        "\n",
        "  print(f\"There are {device_count} GPU(s) available.\")\n",
        "  print(f\"We will use the GPU: {device_name}\")\n",
        "\n",
        "\n",
        "else:\n",
        "  print(\"No GPU available, using the CPU instead.\")\n",
        "  device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKQ-7b2gylVB",
        "outputId": "db2d79b4-0e2c-4c2f-e1bf-77d656c1d259"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU available, using the CPU instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import DistilBertTokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "LoMjH9tPzDm-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PoemDataset(Dataset):\n",
        "    def __init__(self, sentences, poems, tokenizer, max_length):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.inputs = []\n",
        "\n",
        "        for sentence, poem in zip(sentences, poems):\n",
        "            self.inputs.append(f\"{sentence} {poem} {tokenizer.eos_token}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_text = self.inputs[idx]\n",
        "        encodings = self.tokenizer(input_text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
        "        return {\n",
        "            'input_ids': encodings['input_ids'].squeeze(),\n",
        "            'attention_mask': encodings['attention_mask'].squeeze(),\n",
        "        }\n"
      ],
      "metadata": {
        "id": "YMaSSe6WzStR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def prepare_poem_dataset(angry_sentences, funny_poems, model_name='gpt2', max_length=128, batch_size=4):\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    train_sentences, test_sentences, train_poems, test_poems = train_test_split(angry_sentences, funny_poems, test_size=0.2, random_state=42)\n",
        "\n",
        "    train_dataset = PoemDataset(train_sentences, train_poems, tokenizer, max_length)\n",
        "    test_dataset = PoemDataset(test_sentences, test_poems, tokenizer, max_length)\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    return train_dataloader, test_dataloader, tokenizer"
      ],
      "metadata": {
        "id": "_48If9cF3IBS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "angry_sentences = [\n",
        "    \"I can't believe they forgot my birthday!\",\n",
        "    \"This traffic is driving me crazy!\",\n",
        "    \"Why is the WiFi so slow today?\",\n",
        "    \"I'm so tired of eating the same thing every day!\",\n",
        "    \"My phone battery always dies when I need it most!\",\n",
        "    \"Why do I always lose my keys right when I'm late?\",\n",
        "    \"I hate it when people chew with their mouth open!\",\n",
        "    \"How come the line is always longest when I'm in a hurry?\",\n",
        "    \"Why does it always rain when I forget my umbrella?\",\n",
        "    \"I can't stand it when people don't use their turn signals!\"\n",
        "]\n",
        "\n",
        "funny_poems = [\n",
        "    \"Forgotten day, oh what a blight! / But who needs cake at midnight? / Perhaps they plan a grand surprise / Or simply can't read calendar's guise.\",\n",
        "    \"Cars crawl like snails on hot concrete / A turtle race can't be beat / In this jam, I'll grow a beard / Road rage? Nah, I'm just weird.\",\n",
        "    \"Internet crawls, my patience thins / Loading bar becomes my frenemy / I could've trained a pigeon / To deliver emails more speedy.\",\n",
        "    \"Monotonous meals, day after day / My taste buds threaten to run away / Perhaps I'll start a food rebellion / And eat my socks for this meal's hellion.\",\n",
        "    \"Battery drains, oh cruel device! / Always fails at moments precise / I'll invent a phone powered by sighs / Or just yell my messages to the skies.\",\n",
        "    \"Keys play hide and seek, what a game! / As I'm rushing out, they're to blame / I'll tie them to a giant balloon / So finding them won't spell my doom.\",\n",
        "    \"Open-mouthed chewers, please beware / Your dinner sounds pollute the air / I'll invent a mute button for mouths / Or dine exclusively down south.\",\n",
        "    \"Lines stretch long when time is tight / A cosmic joke, an endless plight / I'll master teleportation soon / Or just camp out since last June.\",\n",
        "    \"Raindrops fall as umbrellas hide / Weather forecasts have surely lied / I'll grow a waterproof hairdo / Or just pretend I'm at the zoo.\",\n",
        "    \"Turn signals forgotten, cars swerve / Testing each driver's last nerve / I'll invent telepathic cars / Or stick big arrows to their fars.\"\n",
        "]"
      ],
      "metadata": {
        "id": "aSSACDiB7OOG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Batch keys:\", batch.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7f3EcY4b28L",
        "outputId": "50de0227-f6f7-43a6-b679-c2438fd7c676"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch keys: dict_keys(['input_ids', 'attention_mask'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_dataloader:\n",
        "    print(\"Batch keys:\", batch.keys())\n",
        "    print(\"Input shape:\", batch['input_ids'].shape)\n",
        "    print(\"Attention mask shape:\", batch['attention_mask'].shape)\n",
        "    # Comment out or remove the following line for now\n",
        "    # print(\"Labels shape:\", batch['labels'].shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkFntlHC7EBF",
        "outputId": "d2b4353c-fa8a-4eb5-d3ff-5c99b468e88c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch keys: dict_keys(['input_ids', 'attention_mask'])\n",
            "Input shape: torch.Size([4, 128])\n",
            "Attention mask shape: torch.Size([4, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(train_dataloader, model, optimizer, scheduler, device, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for batch in tqdm(train_dataloader):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(train_dataloader)}\")\n"
      ],
      "metadata": {
        "id": "MdbCkfO22Sfs"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(test_dataloader, model, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_dataloader):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            total_loss += outputs.loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(test_dataloader)\n",
        "    print(f\"Average test loss: {avg_loss}\")"
      ],
      "metadata": {
        "id": "OgHGy5Ej_Ncn"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_poem(sentence, model, tokenizer, device, max_length=128):\n",
        "    model.eval()\n",
        "    input_ids = tokenizer.encode(sentence, return_tensors='pt').to(device)\n",
        "    attention_mask = torch.ones(input_ids.shape, dtype=torch.long, device=device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_length=max_length,\n",
        "            num_return_sequences=1,\n",
        "            do_sample=True,\n",
        "            top_k=50,\n",
        "            top_p=0.95,\n",
        "            temperature=0.7,\n",
        "            no_repeat_ngram_size=2,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    poem = generated_text[len(sentence):].strip()  # Remove the input sentence from the output\n",
        "    lines = poem.split('.')[:4]  # Get first 4 sentences\n",
        "    return '\\n'.join(line.strip() for line in lines if line.strip())\n"
      ],
      "metadata": {
        "id": "nmijXrEd_ed5"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader, test_dataloader, tokenizer = prepare_poem_dataset(angry_sentences, funny_poems)\n",
        "\n",
        "# Set up the model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "model.to(device)\n",
        "\n",
        "# Set up optimizer and scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader) * 10)\n",
        "\n",
        "# Train the model\n",
        "train_model(train_dataloader, model, optimizer, scheduler, device, num_epochs=10)\n",
        "\n",
        "# Generate a poem\n",
        "new_angry_sentence = \"I can't believe I missed my bus!\"\n",
        "generated_poem = generate_poem(new_angry_sentence, model, tokenizer, device)\n",
        "print(f\"Input: {new_angry_sentence}\")\n",
        "print(f\"Generated poem:\\n{generated_poem}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMSWkDg2_hqy",
        "outputId": "81e2fd26-64f6-4b1d-c592-e15443315212"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:20<00:00, 10.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 8.178539752960205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:17<00:00,  8.83s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10, Loss: 4.259954929351807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:16<00:00,  8.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10, Loss: 2.306539297103882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:16<00:00,  8.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10, Loss: 1.912907361984253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:18<00:00,  9.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10, Loss: 1.8905556201934814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:16<00:00,  8.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10, Loss: 1.8167877197265625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:16<00:00,  8.10s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10, Loss: 1.7516024708747864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:16<00:00,  8.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10, Loss: 1.6807235479354858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:17<00:00,  8.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10, Loss: 1.657581090927124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:17<00:00,  8.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, Loss: 1.6297737956047058\n",
            "Input: I can't believe I missed my bus!\n",
            "Generated poem:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gyatc96_Bh0d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}