{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "lzH3tn6wyb4Z"
      },
      "outputs": [],
      "source": [
        "# !pip install wget\n",
        "!pip install torch -q\n",
        "!pip install transformers -q\n",
        "!pip install datasets -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "DWnbuqP3AWCT"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  device_count = torch.cuda.device_count()\n",
        "  device_name = torch.cuda.get_device_name(0)\n",
        "\n",
        "  print(f\"There are {device_count} GPU(s) available.\")\n",
        "  print(f\"We will use the GPU: {device_name}\")\n",
        "\n",
        "\n",
        "else:\n",
        "  print(\"No GPU available, using the CPU instead.\")\n",
        "  device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKQ-7b2gylVB",
        "outputId": "24d4d342-61dd-4981-8a6d-ae8ef77e1966"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU available, using the CPU instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import DistilBertTokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "LoMjH9tPzDm-"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PoemDataset(Dataset):\n",
        "    def __init__(self, sentences, poems, tokenizer, max_length):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.inputs = []\n",
        "\n",
        "        for sentence, poem in zip(sentences, poems):\n",
        "            self.inputs.append(f\"{sentence} {poem} {tokenizer.eos_token}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_text = self.inputs[idx]\n",
        "        encodings = self.tokenizer(input_text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
        "        return {\n",
        "            'input_ids': encodings['input_ids'].squeeze(),\n",
        "            'attention_mask': encodings['attention_mask'].squeeze(),\n",
        "        }\n"
      ],
      "metadata": {
        "id": "YMaSSe6WzStR"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def prepare_poem_dataset(angry_sentences, funny_poems, model_name='gpt2', max_length=128, batch_size=4):\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    train_sentences, test_sentences, train_poems, test_poems = train_test_split(angry_sentences, funny_poems, test_size=0.2, random_state=42)\n",
        "\n",
        "    train_dataset = PoemDataset(train_sentences, train_poems, tokenizer, max_length)\n",
        "    test_dataset = PoemDataset(test_sentences, test_poems, tokenizer, max_length)\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    return train_dataloader, test_dataloader, tokenizer"
      ],
      "metadata": {
        "id": "_48If9cF3IBS"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "angry_sentences = [\n",
        "    \"I can't believe they forgot my birthday!\",\n",
        "    \"This traffic is driving me crazy!\",\n",
        "    \"Why is the WiFi so slow today?\",\n",
        "    \"I'm so tired of eating the same thing every day!\",\n",
        "    \"My phone battery always dies when I need it most!\",\n",
        "    \"Why do I always lose my keys right when I'm late?\",\n",
        "    \"I hate it when people chew with their mouth open!\",\n",
        "    \"How come the line is always longest when I'm in a hurry?\",\n",
        "    \"Why does it always rain when I forget my umbrella?\",\n",
        "    \"I can't stand it when people don't use their turn signals!\"\n",
        "]\n",
        "\n",
        "funny_poems = [\n",
        "    \"Forgotten day, oh what a blight! / But who needs cake at midnight? / Perhaps they plan a grand surprise / Or simply can't read calendar's guise.\",\n",
        "    \"Cars crawl like snails on hot concrete / A turtle race can't be beat / In this jam, I'll grow a beard / Road rage? Nah, I'm just weird.\",\n",
        "    \"Internet crawls, my patience thins / Loading bar becomes my frenemy / I could've trained a pigeon / To deliver emails more speedy.\",\n",
        "    \"Monotonous meals, day after day / My taste buds threaten to run away / Perhaps I'll start a food rebellion / And eat my socks for this meal's hellion.\",\n",
        "    \"Battery drains, oh cruel device! / Always fails at moments precise / I'll invent a phone powered by sighs / Or just yell my messages to the skies.\",\n",
        "    \"Keys play hide and seek, what a game! / As I'm rushing out, they're to blame / I'll tie them to a giant balloon / So finding them won't spell my doom.\",\n",
        "    \"Open-mouthed chewers, please beware / Your dinner sounds pollute the air / I'll invent a mute button for mouths / Or dine exclusively down south.\",\n",
        "    \"Lines stretch long when time is tight / A cosmic joke, an endless plight / I'll master teleportation soon / Or just camp out since last June.\",\n",
        "    \"Raindrops fall as umbrellas hide / Weather forecasts have surely lied / I'll grow a waterproof hairdo / Or just pretend I'm at the zoo.\",\n",
        "    \"Turn signals forgotten, cars swerve / Testing each driver's last nerve / I'll invent telepathic cars / Or stick big arrows to their fars.\"\n",
        "]"
      ],
      "metadata": {
        "id": "aSSACDiB7OOG"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Batch keys:\", batch.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7f3EcY4b28L",
        "outputId": "cdce801a-4cdb-474b-cce5-826a5f50a315"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch keys: dict_keys(['input_ids', 'attention_mask'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader, test_dataloader, tokenizer = prepare_poem_dataset(angry_sentences, funny_poems)\n",
        "for batch in train_dataloader:\n",
        "    print(\"Batch keys:\", batch.keys())\n",
        "    print(\"Input shape:\", batch['input_ids'].shape)\n",
        "    print(\"Attention mask shape:\", batch['attention_mask'].shape)\n",
        "    # Comment out or remove the following line for now\n",
        "    # print(\"Labels shape:\", batch['labels'].shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkFntlHC7EBF",
        "outputId": "f10c36de-2d59-4a5c-a483-1b03b8453ba2"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch keys: dict_keys(['input_ids', 'attention_mask'])\n",
            "Input shape: torch.Size([4, 128])\n",
            "Attention mask shape: torch.Size([4, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDP8RTjXjonm",
        "outputId": "86f738a1-6e00-4a58-ee57-cd32e97a13c8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[   40,  5465,   340,   618,   661, 34722,   351,   511,  5422,  1280,\n",
              "              0,  4946,    12,    76,   448,   704, 34722,   364,    11,  3387,\n",
              "          40600,  1220,  3406,  8073,  5238,  3278,  1133,   262,  1633,  1220,\n",
              "            314,  1183,  8067,   257, 38723,  4936,   329, 28552,  1220,  1471,\n",
              "            288,   500, 11541,   866,  5366,    13,   220, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
              "         [   40,   460,   470,  1975,   484, 16453,   616, 10955,     0, 28586,\n",
              "           1110,    11, 11752,   644,   257, 42514,     0,  1220,   887,   508,\n",
              "           2476, 12187,   379, 15896,    30,  1220,  8673,   484,  1410,   257,\n",
              "           4490,  5975,  1220,  1471,  2391,   460,   470,  1100, 11845,   338,\n",
              "          34731,    13,   220, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
              "         [ 5195,   318,   262, 24904,   523,  3105,  1909,    30,  4455, 27784,\n",
              "           7278,    11,   616, 16336,   294,  1040,  1220, 12320,  2318,  4329,\n",
              "            616, 22832,  3065,  1220,   314,   714,  1053,  8776,   257, 46387,\n",
              "           1220,  1675,  5203,  7237,   517, 35564,    13,   220, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
              "         [   40,   460,   470,  1302,   340,   618,   661,   836,   470,   779,\n",
              "            511,  1210, 10425,     0,  6756, 10425, 11564,    11,  5006,  1509,\n",
              "           3760,  1220, 23983,  1123,  4639,   338,   938, 16384,  1220,   314,\n",
              "           1183,  8067,  5735, 38829,  5006,  1220,  1471,  4859,  1263, 20507,\n",
              "            284,   511,   277,   945,    13,   220, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]]),\n",
              " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(train_dataloader, model, optimizer, scheduler, device, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for batch in tqdm(train_dataloader):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Average loss: {total_loss/len(train_dataloader)}\")\n"
      ],
      "metadata": {
        "id": "MdbCkfO22Sfs"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(test_dataloader, model, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_dataloader):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            total_loss += outputs.loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(test_dataloader)\n",
        "    print(f\"Average test loss: {avg_loss}\")"
      ],
      "metadata": {
        "id": "OgHGy5Ej_Ncn"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_poem(sentence, model, tokenizer, device, max_length=128):\n",
        "    model.eval()\n",
        "    input_ids = tokenizer.encode(sentence, return_tensors='pt').to(device)\n",
        "    attention_mask = torch.ones(input_ids.shape, dtype=torch.long, device=device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "        input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_length=max_length,\n",
        "        num_return_sequences=1,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        temperature=0.8,\n",
        "        no_repeat_ngram_size=2,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        early_stopping=True\n",
        "        )\n",
        "\n",
        "\n",
        "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    poem = generated_text[len(sentence):].strip()  # Remove the input sentence from the output\n",
        "    lines = poem.split('.')[:4]  # Get first 4 sentences\n",
        "    return '\\n'.join(line.strip() for line in lines if line.strip())\n"
      ],
      "metadata": {
        "id": "nmijXrEd_ed5"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader, test_dataloader, tokenizer = prepare_poem_dataset(angry_sentences, funny_poems)\n",
        "\n",
        "# Set up the model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "model.to(device)\n",
        "\n",
        "# Set up optimizer and scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader) * 10)\n",
        "\n",
        "# Train the model\n",
        "train_model(train_dataloader, model, optimizer, scheduler, device, num_epochs=10)\n",
        "\n",
        "# Generate a poem\n",
        "new_angry_sentence = \"I can't believe I missed my bus!\"\n",
        "generated_poem = generate_poem(new_angry_sentence, model, tokenizer, device)\n",
        "print(f\"Input: {new_angry_sentence}\")\n",
        "print(f\"Generated poem:\\n{generated_poem}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMSWkDg2_hqy",
        "outputId": "ba919e67-b28f-4faa-94fb-2e429c458c05"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:39<00:00, 19.96s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Average loss: 8.263564825057983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:17<00:00,  8.82s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10, Average loss: 4.110426187515259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:16<00:00,  8.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10, Average loss: 2.2655410766601562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:16<00:00,  8.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10, Average loss: 1.9162224531173706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:16<00:00,  8.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10, Average loss: 1.831279218196869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:19<00:00,  9.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10, Average loss: 1.806698501110077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:16<00:00,  8.37s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10, Average loss: 1.7153455018997192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:16<00:00,  8.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10, Average loss: 1.691379189491272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:16<00:00,  8.43s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10, Average loss: 1.6599804759025574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:17<00:00,  8.71s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, Average loss: 1.6177828907966614\n",
            "Input: I can't believe I missed my bus!\n",
            "Generated poem:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gyatc96_Bh0d"
      },
      "execution_count": 47,
      "outputs": []
    }
  ]
}