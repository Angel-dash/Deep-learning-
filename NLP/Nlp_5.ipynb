{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8Z_hPizo9hK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploring Sentence-,\n",
        "Document-, and Character Level Embeddings"
      ],
      "metadata": {
        "id": "PGoz4z4kpHdm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "information related to the ordering of words, along with their semantics, can be taken into\n",
        "account when building embeddings to represent words.  \n",
        "Doc2vec which will provide an embedding for entire documents."
      ],
      "metadata": {
        "id": "4jUNuIeJpnHL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " In Learn\n",
        "Natural Language Processing (NLP), along with the word vectors of Learn,\n",
        "Natural, and Language, the Document vector is used to predict the next\n",
        "word, Processing. The model is tuned based on how it did in terms of predicting\n",
        "the word Processing and how it learned throughout"
      ],
      "metadata": {
        "id": "fBL9ByYlrOwy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distributed Bag-of-Words Model of Paragraph Vectors (PV-DBOW): In this\n",
        "approach, word vectors aren't taken into account. Instead, the paragraph vector\n",
        "is used to predict randomly sampled words from the paragraph. In the process of\n",
        "using gradient descent and backpropagation, the paragraph vectors get adjusted\n",
        "and learning happens based on how good or bad they are doing in terms of\n",
        "making predictions. This approach is analogous to the Skip-gram approach used\n",
        "in Word2Vec"
      ],
      "metadata": {
        "id": "ks-F_3VArdGc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building a Doc2Vec model**\n"
      ],
      "metadata": {
        "id": "sUeD6iqQrtnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.test.utils import common_texts\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
      ],
      "metadata": {
        "id": "ddTAUMaspIVn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "common_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ny4UHwRJryzC",
        "outputId": "118cafcb-64f8-41a8-da59-4459074eb21c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['human', 'interface', 'computer'],\n",
              " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
              " ['eps', 'user', 'interface', 'system'],\n",
              " ['system', 'human', 'system', 'eps'],\n",
              " ['user', 'response', 'time'],\n",
              " ['trees'],\n",
              " ['graph', 'trees'],\n",
              " ['graph', 'minors', 'trees'],\n",
              " ['graph', 'minors', 'survey']]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents=[TaggedDocument(doc,[i]) for i,doc in enumerate(common_texts)]\n",
        "documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEqer4Avr09g",
        "outputId": "138db8c4-f7b4-4bcb-f271-2618b5751902"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TaggedDocument(words=['human', 'interface', 'computer'], tags=[0]),\n",
              " TaggedDocument(words=['survey', 'user', 'computer', 'system', 'response', 'time'], tags=[1]),\n",
              " TaggedDocument(words=['eps', 'user', 'interface', 'system'], tags=[2]),\n",
              " TaggedDocument(words=['system', 'human', 'system', 'eps'], tags=[3]),\n",
              " TaggedDocument(words=['user', 'response', 'time'], tags=[4]),\n",
              " TaggedDocument(words=['trees'], tags=[5]),\n",
              " TaggedDocument(words=['graph', 'trees'], tags=[6]),\n",
              " TaggedDocument(words=['graph', 'minors', 'trees'], tags=[7]),\n",
              " TaggedDocument(words=['graph', 'minors', 'survey'], tags=[8])]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Doc2Vec(documents, vector_size=5, min_count=1, workers=4,epochs = 40)\n",
        "model.train(documents, total_examples=model.corpus_count,\n",
        "epochs=model.epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-2EZcAzsM_u",
        "outputId": "6284c3a0-0f8c-4cc2-ca11-2cae8b485a73"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.vector_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7pfP9h6s3Hh",
        "outputId": "38af50ff-a335-48f7-f276-38edc1dbeba3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(model.docvecs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pU1eJaLs9xk",
        "outputId": "267329cf-8792-4ec3-b396-2e8078b582c5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-c8c8dc9618a3>:1: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
            "  len(model.docvecs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(model.wv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OokyLBVctCxE",
        "outputId": "25ec0399-2097-49e5-8b33-ee8e1627391a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = list(model.wv.key_to_index.keys())\n",
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEeicdIhtIQH",
        "outputId": "8dacb3f7-e0b4-4de4-af30-c6d1b5d0dace"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['system',\n",
              " 'graph',\n",
              " 'trees',\n",
              " 'user',\n",
              " 'minors',\n",
              " 'eps',\n",
              " 'time',\n",
              " 'response',\n",
              " 'survey',\n",
              " 'computer',\n",
              " 'interface',\n",
              " 'human']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector=model.infer_vector(['user', 'interface', 'for','computer'])\n",
        "vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3z-f2oKtY2g",
        "outputId": "7c6f5d75-1b92-4e78-bb08-a8beb283c9cb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.05479828,  0.03763286, -0.06908114, -0.07776993,  0.07566229],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changing vector size and min_count"
      ],
      "metadata": {
        "id": "Z02l_G6dvNTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=Doc2Vec(documents, min_count=3,epochs=40,vector_size=50)\n",
        "model.train(documents, total_examples=model.corpus_count,epochs=model.epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFiZ-qttufyg",
        "outputId": "ff79ef76-f43f-41b5-a636-874735c86047"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(model.wv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7wrTizNvptc",
        "outputId": "35fd5cbe-16b6-4c6f-e9d3-eacdb3d8b36d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word=list(model.wv.key_to_index.keys())\n",
        "word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGUL6r-tv_D-",
        "outputId": "01f0dea3-7328-4730-b20e-eb7e17f87211"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['system', 'graph', 'trees', 'user']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector=model.infer_vector(['user', 'interface', 'for','computer'])\n",
        "vector\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n15DZ9smwJhQ",
        "outputId": "32dcd900-699e-4867-b964-7781605b2761"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-5.2483571e-03,  4.0307618e-03, -6.2962021e-03, -7.2687604e-03,\n",
              "        7.4628475e-03, -3.4633225e-03,  1.8517875e-04,  8.7290276e-03,\n",
              "       -9.3542095e-03, -2.9459449e-03,  2.2662533e-03, -6.2356647e-03,\n",
              "        9.4316434e-03, -5.4678768e-03,  8.8230189e-04,  9.0770731e-03,\n",
              "       -5.6036492e-03, -2.1582763e-03, -5.8416356e-03,  6.4541609e-04,\n",
              "        2.6744364e-03,  3.3104499e-03, -1.6974021e-03,  2.9066496e-04,\n",
              "        7.6739360e-03, -2.7164239e-03,  7.2400584e-03,  9.0947598e-03,\n",
              "       -5.2203024e-03, -7.1979202e-03,  4.5083674e-05, -3.4565341e-03,\n",
              "       -8.5999845e-03, -4.5912508e-03, -3.0163312e-03, -4.5598154e-03,\n",
              "        8.0624688e-03,  5.0757970e-03,  7.2172610e-03, -2.6858069e-03,\n",
              "        1.7141332e-03,  7.4147373e-03,  7.2725094e-03,  6.6911322e-03,\n",
              "       -2.3159175e-03,  7.1912785e-03, -1.8938316e-03, -4.5383503e-03,\n",
              "       -2.5647706e-03, -3.5156982e-03], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the vector size is now 50 and only 4 terms are in the vocabulary.\n",
        "This is because min_count was modified to 3 and, consequently, terms that were\n",
        "equal to or greater than 3 terms are present in the vocabulary now."
      ],
      "metadata": {
        "id": "I-zyKAFgwbpD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing two different approaches of doc2vec\n",
        "\n",
        "\n",
        "1.   PV-DM\n",
        "2.   PV-DBOW\n",
        "\n"
      ],
      "metadata": {
        "id": "ZYvBM1lnwki7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=Doc2Vec(documents,vector_size=50,min_count=2,epochs=40,dm=1)\n",
        "model.train(documents,total_examples=model.corpus_count,epochs=model.epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9tDJEh8wVd2",
        "outputId": "5a65e7ea-c369-4f59-9e29-e287e18f4cb9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dm equal to 0 builds the Doc2Vec model based on the distributed bag-of-words approach and vice versa"
      ],
      "metadata": {
        "id": "D7w2wSD0xMJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=Doc2Vec(documents,vector_size=50,min_count=2,epochs=40,dm=0)\n",
        "model.train(documents, total_examples=model.corpus_count,epochs=model.epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fM67JhsxG-g",
        "outputId": "38c7c3a0-f46e-4a91-df42-44e865d92cf6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dm_concat parameter is used in the PV-DM approach. Its value, when set to 1,\n",
        "indicates to the algorithm that the context vectors should be concatenated while trying to\n",
        "predict the target word. This, of course, leads to building a larger model since multiple\n",
        "word embeddings get concatenated."
      ],
      "metadata": {
        "id": "L3_L4q9HxuWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=Doc2Vec(documents,vector_size=50,min_count=2,epochs=40,dm=1,window=2,min_alpha=0.005,dm_concat=1)\n",
        "model.train(documents, total_examples=model.corpus_count,epochs=model.epochs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0mhuZLXxjmK",
        "outputId": "c3db0637-b5b7-4ce1-cedf-89726a50e4cc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The window size parameter controls the distance between the word under concentration\n",
        "and the word to be predicted, similar to the Word2Vec approach."
      ],
      "metadata": {
        "id": "88hGMJAiZhMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=Doc2Vec(documents,vector_size=50,min_count=2,epochs=40,window=2,dm=0)\n",
        "model.train(documents,total_examples=model.corpus_count,epochs=model.epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s17KfNuxyJA0",
        "outputId": "8e90272d-72fe-4806-9b2f-f3a8ac62440f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's explore what the learning rate is and how it can be leveraged."
      ],
      "metadata": {
        "id": "P9qsO_n3Z_K9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " For Doc2Vec,\n",
        "the initial learning rate can be specified using the alpha parameter. With the min_alpha\n",
        "parameter, we can specify what value the learning rate should drop to over the course of\n",
        "training"
      ],
      "metadata": {
        "id": "og0g5JDQaSr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=Doc2Vec(documents, vector_size=50,min_count=2,epochs=40,alpha=0.3,min_alpha=0.05,window=2,dm=1)\n",
        "model.train(documents, epochs=model.epochs,total_examples=model.corpus_count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yauFO3emZ7PU",
        "outputId": "1ce9c177-909c-409d-b839-0d9658e84ffd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploring fastapi"
      ],
      "metadata": {
        "id": "qP0tCZU_IDj9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see the two- and three-character n-grams for the word language:\n",
        "la, lan, an, ang, ng, ngu, gu, gua, ua, uag, ag, age, ge\n",
        "fastText leads to parameter sharing among various words that have any overlapping n-grams. We capture their morphological information from sub-words to build an\n",
        "embedding for the word itself. Also, when certain words are missing from the training\n",
        "vocabulary or rarely occur, we can still have a representation for them if their n-grams are\n",
        "present as part of other words.\n"
      ],
      "metadata": {
        "id": "q5XQ65zeJAth"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why n-grams are useful:\n",
        "\n",
        "Sharing Similarities: The machine can find connections between words that share these n-gram pieces. For example, \"language\" and \"angle\" both have \"an\" and \"ag\" as n-grams, suggesting they might be related in some way.\n",
        "\n",
        "Understanding Unfamiliar Words: If the machine encounters a new word (like \"lingual\") that it hasn't seen before, it can still make some sense of it because \"lingual\" shares n-grams (\"in\", \"gu\") with words it already knows.\n",
        "\n",
        "Basically, n-grams help the machine learn word meanings by looking at smaller building blocks that can appear in many different words. This is especially useful for rare words or for languages with complex morphology (where words are built from smaller meaningful parts)."
      ],
      "metadata": {
        "id": "9td0eKA4JC5p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Buiding a fasttext model**"
      ],
      "metadata": {
        "id": "EAjNNVjaJOj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText\n",
        "from gensim.test.utils import common_texts"
      ],
      "metadata": {
        "id": "uUqXty7aat6E"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "common_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1moPB9qLUMd",
        "outputId": "00c76f45-f3ba-420c-a847-908399108fe3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['human', 'interface', 'computer'],\n",
              " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
              " ['eps', 'user', 'interface', 'system'],\n",
              " ['system', 'human', 'system', 'eps'],\n",
              " ['user', 'response', 'time'],\n",
              " ['trees'],\n",
              " ['graph', 'trees'],\n",
              " ['graph', 'minors', 'trees'],\n",
              " ['graph', 'minors', 'survey']]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastText(vector_size=5, window=3, min_count=1)\n",
        "\n",
        "model.build_vocab(common_texts)\n",
        "model.train(common_texts, total_examples=len(common_texts), epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKGbOhH3JiMl",
        "outputId": "c18699dd-1894-4a43-c8d2-1a3befebcb09"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36, 290)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab=list(model.wv.key_to_index.keys())\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PddemNiKJ7d8",
        "outputId": "04c36551-3c45-424d-b5f5-96fbd04fcab3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['system',\n",
              " 'graph',\n",
              " 'trees',\n",
              " 'user',\n",
              " 'minors',\n",
              " 'eps',\n",
              " 'time',\n",
              " 'response',\n",
              " 'survey',\n",
              " 'computer',\n",
              " 'interface',\n",
              " 'human']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv['human']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deYLCipwLwEs",
        "outputId": "bbd410ff-2822-4c3d-d297-07bd870fbe9d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.03166137,  0.02326731,  0.01241683,  0.00036033,  0.02841445],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(positive=['computer','interface'],negative=['human'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49uzs3pLMu1R",
        "outputId": "e7fd4586-e7fc-4aae-f37d-55f869bd4b44"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('user', 0.7968785762786865),\n",
              " ('system', 0.17462188005447388),\n",
              " ('response', 0.104334257543087),\n",
              " ('survey', 0.009604760445654392),\n",
              " ('trees', -0.07640466839075089),\n",
              " ('time', -0.1330047994852066),\n",
              " ('minors', -0.13927175104618073),\n",
              " ('eps', -0.24093686044216156),\n",
              " ('graph', -0.291752427816391)]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since word representations in FastText are built using the n-grams, min_n, and\n",
        "max_n characters, this helps us by setting the minimum and maximum lengths of\n",
        "the character n-grams so that we can build representations."
      ],
      "metadata": {
        "id": "lScuNlvINNeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=FastText(vector_size=5,window=3,min_count=1, min_n=1, max_n=5)\n",
        "model.build_vocab(common_texts)\n",
        "model.train(common_texts,total_examples=len(common_texts), epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6p-n5-DNFMg",
        "outputId": "478823e6-a47b-4c0d-8f7f-7e4d5d567ce4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36, 290)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv['rubber']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yodUBVXLN4vS",
        "outputId": "3b3358fc-8149-4e8f-f1f7-c3ffaa8dcfb9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.01833104, -0.02146881,  0.00600105, -0.03445042, -0.0165866 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(positive=['computer','human'],negative=['rubber'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umnF9HgXN_cu",
        "outputId": "aaceadc0-de08-4cf7-bf3c-6f36b1dbee5a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('trees', 0.795038104057312),\n",
              " ('eps', 0.7793108820915222),\n",
              " ('minors', 0.2440604716539383),\n",
              " ('time', 0.1623203009366989),\n",
              " ('user', -0.04820726439356804),\n",
              " ('graph', -0.15672056376934052),\n",
              " ('survey', -0.20417772233486176),\n",
              " ('interface', -0.3921482563018799),\n",
              " ('response', -0.6897355914115906),\n",
              " ('system', -0.8435077667236328)]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extending the built model to incorporate words from new sentences"
      ],
      "metadata": {
        "id": "CJ1BcDpNOT-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_to_be_added = [[\"I\", \"am\", \"learning\", \"Natural\", \"Language\", \"Processing\"],\n",
        "                         [\"Natural\", \"Language\", \"Processing\"]]"
      ],
      "metadata": {
        "id": "HhARaqRcONfC"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.build_vocab(sentences_to_be_added, update=True)\n",
        "model.train(common_texts, total_examples=len(sentences_to_be_added), epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCKXEl6TOo7p",
        "outputId": "714650f7-8612-4ca5-fcb0-e0f156daa5e5"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n",
            "WARNING:gensim.models.word2vec:EPOCH 0: supplied example count (9) did not equal expected count (2)\n",
            "WARNING:gensim.models.word2vec:EPOCH 1: supplied example count (9) did not equal expected count (2)\n",
            "WARNING:gensim.models.word2vec:EPOCH 2: supplied example count (9) did not equal expected count (2)\n",
            "WARNING:gensim.models.word2vec:EPOCH 3: supplied example count (9) did not equal expected count (2)\n",
            "WARNING:gensim.models.word2vec:EPOCH 4: supplied example count (9) did not equal expected count (2)\n",
            "WARNING:gensim.models.word2vec:EPOCH 5: supplied example count (9) did not equal expected count (2)\n",
            "WARNING:gensim.models.word2vec:EPOCH 6: supplied example count (9) did not equal expected count (2)\n",
            "WARNING:gensim.models.word2vec:EPOCH 7: supplied example count (9) did not equal expected count (2)\n",
            "WARNING:gensim.models.word2vec:EPOCH 8: supplied example count (9) did not equal expected count (2)\n",
            "WARNING:gensim.models.word2vec:EPOCH 9: supplied example count (9) did not equal expected count (2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 290)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab=list(model.wv.key_to_index.keys())\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPmGL_ZBOtjT",
        "outputId": "971657b0-458f-4373-b451-6255ee4ef335"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Processing',\n",
              " 'Language',\n",
              " 'Natural',\n",
              " 'cool',\n",
              " 'is',\n",
              " 'learning',\n",
              " 'am',\n",
              " 'I',\n",
              " 'M',\n",
              " 'a',\n",
              " 'c',\n",
              " 'h',\n",
              " 'i',\n",
              " 'n',\n",
              " 'e',\n",
              " 'l',\n",
              " 'r',\n",
              " 'g',\n",
              " 's',\n",
              " 't',\n",
              " 'f',\n",
              " 'o',\n",
              " 'm',\n",
              " 'w',\n",
              " 'd']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NBG1wxipQgCW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}